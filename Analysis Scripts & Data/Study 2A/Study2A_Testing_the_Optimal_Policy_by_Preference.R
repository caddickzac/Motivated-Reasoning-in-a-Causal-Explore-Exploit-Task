############################################
# Testing the Optimal Policy by Preference #
############################################

# Note: two data (.csv) files are used in this script.
# Analysis #1: replication of study 1 (Congruent vs Incongruent Analysis)
# Analysis #2: strong vs weak preferences.

# Import Libraries
library("tidyverse")
library('lmerTest')

#####################################
# Congruent vs Incongruent Analysis #
#####################################

# Import data
Study2A_Testing_the_Optimal_Policy_by_Preference_study1_replication <- as_tibble(read.csv("Study2A_Testing_the_Optimal_Policy_by_Preference_study1_replication.csv"))

# Preview data
head(Study2A_Testing_the_Optimal_Policy_by_Preference_study1_replication)

# data dictionary:
## "Participant" = participant number
## "Trial" = trial number (range: 11-150; only includes trials which participant had control of policies decisions)
## "Optimal_Policy_Selected" = Notes whether optimal policy (i.e., the policy choice that yields maximum output over time; 1=yes, -1=no) 
## "Ambiguity" = Notes whether function ambiguity type (low or high)
## "Congruence" = Notes whether optimal policy choice was also participants preferred policy (1=yes; -1=no)


OP_Study_1_replication <- Study2A_Testing_the_Optimal_Policy_by_Preference_study1_replication %>%
  group_by(Participant, Ambiguity, Congruence)%>%
  summarize(mean_Optimal_Policy_Selected=mean(Optimal_Policy_Selected),
            n=n())

# Code for checking randomization outcomes: 
# View(OP_Study_1_replication)
# 
# OP_Study_1_replication_2<-OP_Study_1_replication %>%
#   group_by(Participant)%>%
#   summarize(n=n())
# sum(OP_Study_1_replication_2$n==1) #26
# sum(OP_Study_1_replication_2$n==2) #54
# sum(OP_Study_1_replication_2$n==3) #8
# sum(OP_Study_1_replication_2$n==4) #0 people have one function of each type (i.e., all combinations of 2x2 outcomes for ambiguity (low vs high) and preference-congruence (yes vs no))


# use effects coding for model
OP_Study_1_replication$Ambiguity2 <- ifelse(OP_Study_1_replication$Ambiguity=='Low',.5,-.5)
OP_Study_1_replication$Congruence2 <- ifelse(OP_Study_1_replication$Congruence==1,.5,-.5)


m1 <- lmer(mean_Optimal_Policy_Selected ~ Congruence2*Ambiguity2 +
                  (1+Congruence2*Ambiguity2|Participant),
                data=OP_Study_1_replication)
# Error: number of observations (=158) <= number of random effects (=352) for term (1 + Congruence2 * Ambiguity2 | User); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

m2 <- lmer(mean_Optimal_Policy_Selected ~ Congruence2*Ambiguity2 +
                  (1+Congruence2*Ambiguity2||Participant),
                data=OP_Study_1_replication)
summary(m2)

# Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
# Formula: mean_Optimal_Policy_Selected ~ Congruence2 * Ambiguity2 + (1 +      Congruence2 * Ambiguity2 || Participant)
#    Data: OP_Study_1_replication
# 
# REML criterion at convergence: 63.5
# 
# Scaled residuals: 
#      Min       1Q   Median       3Q      Max 
# -1.27194 -0.39522 -0.03667  0.35796  1.87628 
# 
# Random effects:
#  Groups        Name                   Variance Std.Dev.
#  Participant   (Intercept)            0.001447 0.03804 
#  Participant.1 Congruence2            0.079263 0.28154 
#  Participant.2 Ambiguity2             0.143847 0.37927 
#  Participant.3 Congruence2:Ambiguity2 0.001410 0.03755 
#  Residual                             0.031600 0.17776 
# Number of obs: 158, groups:  Participant, 88
# 
# Fixed effects:
#                        Estimate Std. Error       df t value Pr(>|t|)    
# (Intercept)             0.53267    0.01841 57.68510  28.929  < 2e-16 ***
# Congruence2             0.33648    0.04853 77.98148   6.933 1.06e-09 ***
# Ambiguity2              0.37759    0.05405 80.51739   6.986 7.34e-10 ***
# Congruence2:Ambiguity2 -0.05317    0.07427 51.59956  -0.716    0.477    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#             (Intr) Cngrn2 Ambgt2
# Congruence2 -0.022              
# Ambiguity2   0.005 -0.004       
# Cngrnc2:Am2 -0.032 -0.004 -0.021

#----------------------------------------------------------

####################################################
# Strong Preference vs Neutral Preference Analysis #
####################################################

# import data
Study2A_Testing_the_Optimal_Policy_by_Preference_strong_vs_neutral_preferences <- as_tibble(read.csv("Study2A_Testing_the_Optimal_Policy_by_Preference_strong_vs_neutral_preferences.csv"))

# preview data
head(Study2A_Testing_the_Optimal_Policy_by_Preference_strong_vs_neutral_preferences)

# data dictionary:
## "Participant" = participant number
## "Trial" = trial number (range: 11-150; only includes trials which participant had control of policies decisions)
## "Optimal_Policy_Selected" = Notes whether optimal policy (i.e., the policy choice that yields maximum output over time; 1=yes, 0=no) 
## "Ambiguity" = Notes whether function ambiguity type (low or high)
## "Congruence" = Notes whether optimal policy choice was also participants preferred policy (1=yes; -1=no, -88 = neutral policy)
## "Preference_Strength" = notes whether participant held strong (either in favor of or against a policy) or neutral (neither for nor against) stance for a given policy 

OP_Strong_vs_Neutral_Preferences <-Study2A_Testing_the_Optimal_Policy_by_Preference_strong_vs_neutral_preferences %>%
  group_by(Participant, Ambiguity, Preference_Strength)%>%
  summarize(mean_Optimal_Policy_Selected=mean(Optimal_Policy_Selected),
            n=n())

OP_Strong_vs_Neutral_Preferences2 <-OP_Strong_vs_Neutral_Preferences %>%
  group_by(Participant)%>%
  summarize(n=n())
sum(OP_df_S2A_strong_vs_neutral_simple_2$n==1) #0
sum(OP_df_S2A_strong_vs_neutral_simple_2$n==2) #18
sum(OP_df_S2A_strong_vs_neutral_simple_2$n==3) #34
sum(OP_df_S2A_strong_vs_neutral_simple_2$n==4) #36 people have one function of each type


# effects coding for predictors
OP_Strong_vs_Neutral_Preferences$Ambiguity2 <- ifelse(OP_Strong_vs_Neutral_Preferences$Ambiguity=="Low", .5, -.5)
OP_Strong_vs_Neutral_Preferences$Preference_Strength2 <- ifelse(OP_Strong_vs_Neutral_Preferences$Preference_Strength=="Neutral",.5,-.5)


m1 <- lmer(mean_Optimal_Policy_Selected ~ Preference_Strength2*Ambiguity2 +
                       (1+Preference_Strength2*Ambiguity2|Participant),
                     data=OP_Strong_vs_Neutral_Preferences)
# Error: number of observations (=282) <= number of random effects (=352) for term (1 + Preference_Strength2 * Ambiguity2 | Participant); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

m2 <- lmer(mean_Optimal_Policy_Selected ~ Preference_Strength2*Ambiguity2 +
                       (1+Preference_Strength2*Ambiguity2||Participant),
                     data=OP_Strong_vs_Neutral_Preferences)
# convergence issues
# Fixed effects:
#   Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)                      0.546801   0.016907 81.378705  32.343  < 2e-16 ***
#   Preference_Strength2            -0.004878   0.035134 91.111728  -0.139    0.890    
# Ambiguity2                       0.411984   0.045469 87.823340   9.061 3.13e-14 ***
#   Preference_Strength2:Ambiguity2  0.059290   0.064962 87.144997   0.913    0.364


# model presented in paper
m3 <- lmer(mean_Optimal_Policy_Selected ~ Preference_Strength2*Ambiguity2 +
                       (1+Preference_Strength2+Ambiguity2||Participant),
                     data=OP_Strong_vs_Neutral_Preferences)
summary(m3)
# Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
# Formula: mean_Optimal_Policy_Selected ~ Preference_Strength2 * Ambiguity2 +      (1 + Preference_Strength2 + Ambiguity2 || Participant)
#    Data: OP_Strong_vs_Neutral_Preferences
# 
# REML criterion at convergence: 148.4
# 
# Scaled residuals: 
#      Min       1Q   Median       3Q      Max 
# -2.25459 -0.63994  0.08437  0.54482  1.86427 
# 
# Random effects:
#  Groups        Name                 Variance Std.Dev.
#  Participant   (Intercept)          0.002128 0.04613 
#  Participant.1 Preference_Strength2 0.011013 0.10494 
#  Participant.2 Ambiguity2           0.087791 0.29630 
#  Residual                           0.071481 0.26736 
# Number of obs: 282, groups:  Participant, 88
# 
# Fixed effects:
#                                  Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)                      0.546801   0.016907 81.378764  32.343  < 2e-16 ***
# Preference_Strength2            -0.004878   0.035134 91.111760  -0.139    0.890    
# Ambiguity2                       0.411984   0.045469 87.822654   9.061 3.13e-14 ***
# Preference_Strength2:Ambiguity2  0.059290   0.064962 87.144891   0.913    0.364    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#             (Intr) Prf_S2 Ambgt2
# Prfrnc_Str2 0.001               
# Ambiguity2  0.027  0.011        
# Prfrn_S2:A2 0.017  0.043  0.001
