############################################
# Testing the Optimal Policy by Preference #
############################################

# Note: two data (.csv) files are used in this script.
# Analysis #1: replication of study 1 (Congruent vs Incongruent Analysis)
# Analysis #2: strong vs weak preferences.


# Import Libraries
library("tidyverse")
library('lmerTest')

#####################################
# Congruent vs Incongruent Analysis #
#####################################

# Import data
Study2B_Testing_the_Optimal_Policy_by_Preference_study1_replication <- as_tibble(read.csv("Study2B_Testing_the_Optimal_Policy_by_Preference_study1_replication.csv"))

# Preview data
head(Study2B_Testing_the_Optimal_Policy_by_Preference_study1_replication)

# data dictionary:
## "Participant" = participant number
## "Trial" = trial number (range: 11-150; only includes trials which participant had control of policies decisions)
## "Optimal_Policy_Selected" = Notes whether optimal policy (i.e., the policy choice that yields maximum output over time; 1=yes, -1=no) 
## "Ambiguity" = Notes whether function ambiguity type (low or high)
## "Congruence" = Notes whether optimal policy choice was also participants preferred policy (1=yes; -1=no)


OP_Study_1_replication <- Study2B_Testing_the_Optimal_Policy_by_Preference_study1_replication %>%
  group_by(Participant, Ambiguity, Congruence)%>%
  summarize(mean_Optimal_Policy_Selected=mean(Optimal_Policy_Selected),
            n=n())

# Code for checking randomization outcomes: 
# View(OP_Study_1_replication)
# 
# OP_Study_1_replication_2<-OP_Study_1_replication %>%
#   group_by(Participant)%>%
#   summarize(n=n())
# sum(OP_Study_1_replication_2$n==1) #92
# sum(OP_Study_1_replication_2$n==2) #157
# sum(OP_Study_1_replication_2$n==3) #28
# sum(OP_Study_1_replication_2$n==4) #3 people have one function of each type (i.e., all combinations of 2x2 outcomes for ambiguity (low vs high) and preference-congruence (yes vs no))


# use effects coding for model
OP_Study_1_replication$Ambiguity2 <- ifelse(OP_Study_1_replication$Ambiguity=='Low',.5,-.5)
OP_Study_1_replication$Congruence2 <- ifelse(OP_Study_1_replication$Congruence==1,.5,-.5)


# m1 <- lmer(mean_Optimal_Policy_Selected ~ Congruence2*Ambiguity2 +
#              (1+Congruence2*Ambiguity2|Participant),
#            data=OP_Study_1_replication)
# Error: number of observations (=502) <= number of random effects (=1120) for term (1 + Congruence2 * Ambiguity2 | Participant); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

# m2 <- lmer(mean_Optimal_Policy_Selected ~ Congruence2*Ambiguity2 +
#              (1+Congruence2*Ambiguity2||Participant),
#            data=OP_Study_1_replication)
# failed to converge

m3 <- lmer(mean_OP_Coded ~ Congruence_Coded2*Ambiguity2 +
                  (1+Congruence_Coded2+Ambiguity2||User),
                data=OP_dfz_simple_Study2B)
summary(m3)

# Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
# Formula: mean_OP_Coded ~ Congruence_Coded2 * Ambiguity2 + (1 + Congruence_Coded2 +      Ambiguity2 || User)
#    Data: OP_dfz_simple_Study2B
# 
# REML criterion at convergence: 226.9
# 
# Scaled residuals: 
#      Min       1Q   Median       3Q      Max 
# -2.17840 -0.31783 -0.00728  0.30380  2.10941 
# 
# Random effects:
#  Groups   Name              Variance Std.Dev.
#  User     (Intercept)       0.01453  0.1205  
#  User.1   Congruence_Coded2 0.11144  0.3338  
#  User.2   Ambiguity2        0.10310  0.3211  
#  Residual                   0.02506  0.1583  
# Number of obs: 502, groups:  User, 280
# 
# Fixed effects:
#                               Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)                    0.52699    0.01268 201.48260  41.559   <2e-16 ***
# Congruence_Coded2              0.26498    0.02940 254.90704   9.013   <2e-16 ***
# Ambiguity2                     0.43926    0.02794 241.22535  15.720   <2e-16 ***
# Congruence_Coded2:Ambiguity2   0.01683    0.04479 234.03329   0.376    0.707    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#             (Intr) Cng_C2 Ambgt2
# Cngrnc_Cdd2  0.010              
# Ambiguity2  -0.020 -0.016       
# Cngrn_C2:A2 -0.047 -0.010  0.007

#----------------------------------------------------------

####################################################
# Strong Preference vs Neutral Preference Analysis #
####################################################

# import data
Study2B_Testing_the_Optimal_Policy_by_Preference_strong_vs_neutral_preferences <- as_tibble(read.csv("Study2B_Testing_the_Optimal_Policy_by_Preference_strong_vs_neutral_preferences.csv"))


OP_Strong_vs_Neutral_Preferences <-Study2B_Testing_the_Optimal_Policy_by_Preference_strong_vs_neutral_preferences %>%
  group_by(Participant, Ambiguity, Preference_Strength)%>%
  summarize(mean_Optimal_Policy_Selected=mean(Optimal_Policy_Selected),
            n=n())

OP_Strong_vs_Neutral_Preferences2 <-OP_Strong_vs_Neutral_Preferences %>%
  group_by(Participant)%>%
  summarize(n=n())
# checking randomization outcomes
# sum(OP_df_S2B_strong_vs_neutral_simple_2$n==1) # 0
# sum(OP_df_S2B_strong_vs_neutral_simple_2$n==2) # 59
# sum(OP_df_S2B_strong_vs_neutral_simple_2$n==3) # 113
# sum(OP_df_S2B_strong_vs_neutral_simple_2$n==4) # 111 people have one function of each type


# effects coding for predictors
OP_Strong_vs_Neutral_Preferences$Ambiguity2 <- ifelse(OP_Strong_vs_Neutral_Preferences$Ambiguity=="Low", .5, -.5)
OP_Strong_vs_Neutral_Preferences$Preference_Strength2 <- ifelse(OP_Strong_vs_Neutral_Preferences$Preference_Strength=="Neutral",.5,-.5)


m1 <- lmer(mean_Optimal_Policy_Selected ~ Preference_Strength2*Ambiguity2 +
             (1+Preference_Strength2*Ambiguity2|Participant),
           data=OP_Strong_vs_Neutral_Preferences)
# Error: number of observations (=901) <= number of random effects (=1132) for term (1 + Preference_Strength2 * Ambiguity2 | Participant); the random-effects parameters and the residual variance (or scale parameter) are probably unidentifiable

m2 <- lmer(mean_Optimal_Policy_Selected ~ Preference_Strength2*Ambiguity2 +
             (1+Preference_Strength2*Ambiguity2||Participant),
           data=OP_Strong_vs_Neutral_Preferences)
# convergence issues



# model presented in paper
m3 <- lmer(mean_Optimal_Policy_Selected ~ Preference_Strength2*Ambiguity2 +
             (1+Preference_Strength2+Ambiguity2||Participant),
           data=OP_Strong_vs_Neutral_Preferences)
summary(m3)
# Linear mixed model fit by REML. t-tests use Satterthwaite's method ['lmerModLmerTest']
# Formula: mean_Optimal_Policy_Selected ~ Preference_Strength2 * Ambiguity2 +      (1 + Preference_Strength2 + Ambiguity2 || Participant)
#    Data: OP_Strong_vs_Neutral_Preferences
# 
# REML criterion at convergence: 424.4
# 
# Scaled residuals: 
#     Min      1Q  Median      3Q     Max 
# -2.5748 -0.6742  0.0983  0.5447  2.3658 
# 
# Random effects:
#  Groups        Name                 Variance Std.Dev.
#  Participant   (Intercept)          0.002898 0.05383 
#  Participant.1 Preference_Strength2 0.006377 0.07985 
#  Participant.2 Ambiguity2           0.053862 0.23208 
#  Residual                           0.075473 0.27472 
# Number of obs: 901, groups:  Participant, 283
# 
# Fixed effects:
#                                  Estimate Std. Error        df t value Pr(>|t|)    
# (Intercept)                     5.391e-01  9.807e-03 2.919e+02  54.971   <2e-16 ***
# Preference_Strength2            2.906e-02  1.945e-02 2.710e+02   1.494    0.136    
# Ambiguity2                      4.508e-01  2.319e-02 2.852e+02  19.442   <2e-16 ***
# Preference_Strength2:Ambiguity2 8.479e-03  3.728e-02 2.765e+02   0.227    0.820    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#             (Intr) Prf_S2 Ambgt2
# Prfrnc_Str2 -0.014              
# Ambiguity2  -0.010  0.017       
# Prfrn_S2:A2  0.017 -0.015 -0.011
