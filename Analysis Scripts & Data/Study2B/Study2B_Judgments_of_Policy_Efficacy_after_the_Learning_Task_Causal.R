#######################################
# Judgment Accuracy: Causal Functions #
#######################################

#import libraries
library('lmerTest') 
library("tidyverse")

# Import data
Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal <- as_tibble(read.csv("Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal.csv"))

# Preview data
head(Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal)

# data dictionary:
## "Participant" = participant number
## "Function" = function number (causal functions only; range 1-4; refer to payoff function figure)
## "Congruence" = denotes preference-congruence for a given policy/function
## "Ambiguity" = denotes ambiguity of function (low vs high)
## "Judgment_Accuracy" = values are the distance a final judgment was from the correct assessment value (3 possible values: 0-2); 0=correct judgment; 1=incorrect (policy A = policy B); 2=incorrect (e.g., Policy A < Policy B)


# Re-coded judgment accuracy so that correct=1 and incorrect judgment=0 
Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Judgment_Accuracy_Coded <-
  ifelse(Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Judgment_Accuracy==0, 1, 0)

# Descriptives: average judgment accuracy across congruence and ambiguity
tapply(Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Judgment_Accuracy_Coded,
       list(Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Ambiguity,
            Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Congruence),
       mean,
       na.rm=TRUE) 

# Effects coding for model
Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Ambiguity2 <-
  ifelse(Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Ambiguity=="Low",.5,-.5)

##################################################
# Preference-Congruence vs Incongruence Analysis #
##################################################

# subset data 
jpe_causal_preference_only <- Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal %>% 
  filter(!Congruence %in% "Neutral")

# Effects coding for model
jpe_causal_preference_only$Congruence2 <-
  ifelse(jpe_causal_preference_only$Congruence=="Congruent", .5,-.5)

#------------------------------------------

# logistic regression: Congruent vs Incongruent Analysis

m1 <- lmer(mean_Optimal_Policy_Selected ~ Congruence2*Ambiguity2 +
             (1+Congruence2*Ambiguity2|Participant),
           data=OP_Study_1_replication)

# Maximal Model
# m1 <- glmer(Judgment_Accuracy_Coded ~ Congruence2*Ambiguity2 +
#               (1+Congruence2*Ambiguity2|Participant),
#             data=jpe_causal_preference_only, family="binomial",
#             control=glmerControl(optimizer="bobyqa"))
# Error: number of observations (=555) < number of random effects (=1120) for term (1 + Congruence2 * Ambiguity2 | Participant); the random-effects parameters are probably unidentifiable

# m2 <- glmer(Judgment_Accuracy_Coded ~ Congruence2*Ambiguity2 + 
#               (1+Congruence2*Ambiguity2||Participant),
#             data=jpe_causal_preference_only, family="binomial",
#             control=glmerControl(optimizer="bobyqa"))
# Model failed to converge: degenerate  Hessian with 1 negative eigenvalues

# m3 <- glmer(Judgment_Accuracy_Coded ~ Congruence2*Ambiguity2 +
#               (0+Congruence2*Ambiguity2|Participant),
#             data=jpe_causal_preference_only, family="binomial",
#             control=glmerControl(optimizer="bobyqa"))
# Error: number of observations (=555) < number of random effects (=840) for term (0 + Congruence2 * Ambiguity2 | Participant); the random-effects parameters are probably unidentifiable

# m4 <- glmer(Judgment_Accuracy_Coded ~ Congruence2*Ambiguity2 + 
#               (1+Congruence2+Ambiguity2|Participant),
#             data=jpe_causal_preference_only, family="binomial",
#             control=glmerControl(optimizer="bobyqa"))
# Error: number of observations (=555) < number of random effects (=840) for term (1 + Congruence2 + Ambiguity2 | Participant); the random-effects parameters are probably unidentifiable

m5 <- glmer(Judgment_Accuracy_Coded ~ Congruence2*Ambiguity2 + 
              (1+Congruence2+Ambiguity2||Participant),
            data=jpe_causal_preference_only, family="binomial",
            control=glmerControl(optimizer="bobyqa"))
summary(m5)

# Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
# Family: binomial  ( logit )
# Formula: Judgment_Accuracy_Coded ~ Congruence2 * Ambiguity2 + (1 + Congruence2 +      Ambiguity2 || Participant)
# Data: jpe_causal_preference_only
# Control: glmerControl(optimizer = "bobyqa")
# 
# AIC      BIC   logLik deviance df.resid 
# 417.1    447.3   -201.6    403.1      548 
# 
# Scaled residuals: 
#   Min       1Q   Median       3Q      Max 
# -1.01831 -0.00925  0.00028  0.00756  1.01386 
# 
# Random effects:
#   Groups        Name        Variance Std.Dev.
# Participant   (Intercept) 244.9    15.65   
# Participant.1 Congruence2 938.4    30.63   
# Participant.2 Ambiguity2  761.9    27.60   
# Number of obs: 555, groups:  Participant, 280
# 
# Fixed effects:
#   Estimate Std. Error z value Pr(>|z|)    
# (Intercept)              0.3141     0.6056   0.519    0.604    
# Congruence2              2.3136     1.4228   1.626    0.104    
# Ambiguity2              21.2789     1.8997  11.201   <2e-16 ***
#   Congruence2:Ambiguity2   0.3275     2.3284   0.141    0.888    
# ---
#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#   (Intr) Cngrn2 Ambgt2
# Congruence2 0.104               
# Ambiguity2  0.112  0.462        
# Cngrnc2:Am2 0.498  0.133  0.037 

#-----------------------------------------------------------------------------------------

#########################################
# Strong vs Neutral Preference Analysis #
#########################################

# Create new predictor variable with effects coding that compares strong vs neutral preference 
Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Preference_Strength <-
  ifelse(Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal$Congruence=="Neutral",.5,-.5)

# Maximal Model
# m1 <- glmer(Judgment_Accuracy_Coded ~ Preference_Strength*Ambiguity2 + 
#               (1+Preference_Strength*Ambiguity2|Participant),
#             data=Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal, family="binomial",
#             control=glmerControl(optimizer="bobyqa"))
# convergence issues

m2 <- glmer(Judgment_Accuracy_Coded ~ Preference_Strength*Ambiguity2 + 
              (1+Preference_Strength*Ambiguity2||Participant),
            data=Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal, family="binomial",
            control=glmerControl(optimizer="bobyqa"))
summary(m2)

# Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
# Family: binomial  ( logit )
# Formula: Judgment_Accuracy_Coded ~ Preference_Strength * Ambiguity2 +      (1 + Preference_Strength * Ambiguity2 || Participant)
# Data: Study2B_Judgments_of_Policy_Efficacy_after_the_Learning_Task_Causal
# Control: glmerControl(optimizer = "bobyqa")
# 
# AIC      BIC   logLik deviance df.resid 
# 1157.4   1197.7   -570.7   1141.4     1124 
# 
# Scaled residuals: 
#   Min      1Q  Median      3Q     Max 
# -1.8102 -0.3175  0.2553  0.3494  1.6129 
# 
# Random effects:
#   Groups        Name                           Variance  Std.Dev. 
# Participant   (Intercept)                    6.103e-01 7.812e-01
# Participant.1 Preference_Strength            4.626e-13 6.802e-07
# Participant.2 Ambiguity2                     8.344e+00 2.889e+00
# Participant.3 Preference_Strength:Ambiguity2 0.000e+00 0.000e+00
# Number of obs: 1132, groups:  Participant, 283
# 
# Fixed effects:
#   Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                     0.20068    0.10110   1.985   0.0471 *  
#   Preference_Strength             0.09317    0.18867   0.494   0.6214    
# Ambiguity2                      3.79520    0.38862   9.766   <2e-16 ***
#   Preference_Strength:Ambiguity2 -0.04703    0.36744  -0.128   0.8981    
# ---
#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#   (Intr) Prfr_S Ambgt2
# Prfrnc_Strn -0.009              
# Ambiguity2   0.128  0.065       
# Prfrnc_S:A2  0.036  0.043 -0.015
