################################################
# Number of Trials Until Testing by Preference #
################################################

# Import Libraries
library("tidyverse")
library('lmerTest')

# Import data
Number_of_Trials_Until_Testing_by_Preference <- read.csv("Study1_Number_of_Trials_Until_Testing_by_Preference.csv")

# preview data
head(Number_of_Trials_Until_Testing_by_Preference)

# data dictionary:
## "Participant" = participant number
## "Function" = Function number (range 1-6; refer to payoff function figure)
## "Preferred_Policy_at_Start" = notes preferred policy at start (or not); 1 = randomized to preferred policy at start of learning task; 0 = non preferred policy at start 
## "Trial_Number_of_First_Test" = Notes what trial number a participant made first test (i.e., change/switch) for a given policy/function; Note "NA"s mean a participant never tested a policy/function. Also note that trial 1-10 were learning trials, where a participant did not have control yet.

# Subtract 10 from trial number, to reflect trial # that participant actually had control of economic policies. 
Number_of_Trials_Until_Testing_by_Preference$first_test_adj <- 
  Number_of_Trials_Until_Testing_by_Preference$Trial_Number_of_First_Test - 10

# Descriptives: When did participants first test policies across (initially set to) preferred vs nonpreferred policies
aggregate(Number_of_Trials_Until_Testing_by_Preference$first_test_adj, 
          by=list(Number_of_Trials_Until_Testing_by_Preference$Preferred_Policy_at_Start),
          mean, na.rm=T)

# Use effects coding for analysis
Number_of_Trials_Until_Testing_by_Preference$Preferred_Policy_at_Start_Coded <- 
  ifelse(Number_of_Trials_Until_Testing_by_Preference$Preferred_Policy_at_Start==1, .5, 
         ifelse(Number_of_Trials_Until_Testing_by_Preference$Preferred_Policy_at_Start==0, -.5,""))
Number_of_Trials_Until_Testing_by_Preference$Preferred_Policy_at_Start_Coded2 <- 
  as.double(Number_of_Trials_Until_Testing_by_Preference$Preferred_Policy_at_Start)

# Re-scale to improve model convergence (z-score with min. value of 1)
Number_of_Trials_Until_Testing_by_Preference$first_test_adj_centered <- 
  scale(Number_of_Trials_Until_Testing_by_Preference$first_test_adj, center=TRUE)
Number_of_Trials_Until_Testing_by_Preference$first_test_adj_centered_fixed <- 
  Number_of_Trials_Until_Testing_by_Preference$first_test_adj_centered + 
  abs(min(Number_of_Trials_Until_Testing_by_Preference$first_test_adj_centered,na.rm=T)) + 
  1

# Model: 
model <- glmer(first_test_adj_centered_fixed ~ Preferred_Policy_at_Start_Coded2 + (1+Preferred_Policy_at_Start_Coded2|Participant),
            data=Number_of_Trials_Until_Testing_by_Preference, family=Gamma(link='inverse'))
summary(model)

# Output
# Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) ['glmerMod']
# Family: Gamma  ( inverse )
# Formula: first_test_adj_centered_fixed ~ Preferred_Policy_at_Start_Coded2 +      (1 + Preferred_Policy_at_Start_Coded2 | Participant)
# Data: Number_of_Trials_Until_Testing_by_Preference
# 
# AIC      BIC   logLik deviance df.resid 
# 285.4    306.0   -136.7    273.4      221 
# 
# Scaled residuals: 
#   Min      1Q  Median      3Q     Max 
# -1.7176 -0.3498 -0.1049  0.1746  3.6872 
# 
# Random effects:
#   Groups      Name                             Variance Std.Dev. Corr 
# Participant (Intercept)                      0.03341  0.1828        
# Preferred_Policy_at_Start_Coded2 0.03640  0.1908   -0.68
# Residual                                     0.10559  0.3249        
# Number of obs: 227, groups:  Participant, 41
# 
# Fixed effects:
#   Estimate Std. Error t value Pr(>|z|)    
# (Intercept)                       0.92927    0.04725  19.668  < 2e-16 ***
#   Preferred_Policy_at_Start_Coded2 -0.29947    0.05142  -5.824 5.76e-09 ***
#   ---
#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Correlation of Fixed Effects:
#   (Intr)
# Prf_P__S_C2 -0.655

########################################################################
