####################################################################
# Percent of Trials During which the Preferred Option Was Selected #
####################################################################

# Import Libaries
library("tidyverse")
library('lsr') # used for "CohensD" function

# Import data
Study1_Amount_of_Testing_by_Preference <- read.csv('Study1_Amount_of_Testing_by_Preference.csv')

# preview data
head(Study1_Amount_of_Testing_by_Preference)

# data dictionary: 
## "Participant" = participant number
## "Trial" = learning trial number (ranges: 0-151). Participants could only change input on trials 11-150 (1-10 were for learning purposes, and trial 151 was for final assessments of policies)
##  "F1_Pref_Policy" = Notes whether or not Function 1 was set to a preferred policy (coded as 1) or not (coded as 0)
##  "F2_Pref_Policy" = Notes whether or not Function 2 was set to a preferred policy (coded as 1) or not (coded as 0)
##  "F3_Pref_Policy" = Notes whether or not Function 3 was set to a preferred policy (coded as 1) or not (coded as 0)
##  "F4_Pref_Policy" = Notes whether or not Function 4 was set to a preferred policy (coded as 1) or not (coded as 0)
##  "F5_Pref_Policy" = Notes whether or not Function 5 was set to a preferred policy (coded as 1) or not (coded as 0)
##  "F6_Pref_Policy" = Notes whether or not Function 6 was set to a preferred policy (coded as 1) or not (coded as 0)

# Filter to only include trials where participants had control over policy choice (trials 1-150).  
Study1_Amount_of_Testing_by_Preference <- Study1_Amount_of_Testing_by_Preference %>% 
  filter(Trial %in% c(11:150))

# Create dataframe with percent of preferred policy for each function
Study1_Amount_of_Testing_by_Preference_Mean_Output <- Study1_Amount_of_Testing_by_Preference %>%
  group_by(Participant) %>% 
  summarise_at(.vars = vars(F1_Pref_Policy,
                            F2_Pref_Policy,
                            F3_Pref_Policy,
                            F4_Pref_Policy,
                            F5_Pref_Policy,
                            F6_Pref_Policy
  ),
  .funs= c(mean="mean"), na.rm=TRUE)

# examine output ()
head(Study1_Amount_of_Testing_by_Preference_Mean_Output)

# Aggregate output by causal (1-4) and non causal (5-6) functions
Study1_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean <- 
(Study1_Amount_of_Testing_by_Preference_Mean_Output$F1_Pref_Policy_mean+
  Study1_Amount_of_Testing_by_Preference_Mean_Output$F2_Pref_Policy_mean+
  Study1_Amount_of_Testing_by_Preference_Mean_Output$F3_Pref_Policy_mean+
  Study1_Amount_of_Testing_by_Preference_Mean_Output$F4_Pref_Policy_mean)/4

Study1_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean <- 
  (Study1_Amount_of_Testing_by_Preference_Mean_Output$F5_Pref_Policy_mean+
        Study1_Amount_of_Testing_by_Preference_Mean_Output$F6_Pref_Policy_mean)/2

# Causal Functions: Descriptives
round(mean(Study1_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean),4)*100 # Mean
round(sd(Study1_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean),4)*100 # Std dev

# Causal Functions: one-sample t-test
t.test(Study1_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean, mu=.50) # t(40)=5.93, p < .001

# Causal Functions: Cohen's d (one-sample t-test)
cohensD(Study1_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean, mu=.50) # d = .93

# Non-Causal Functions: Descriptives
round(mean(Study1_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean),4)*100 # Mean
round(sd(Study1_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean),4)*100 # Std dev

# Non-Causal Functions: one-sample t-test
t.test(Study1_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean, mu=.50) # t(40)=6.79, p < .001

# Non-Causal Functions: Cohen's d (one-sample t-test)
cohensD(Study1_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean, mu=.50) # d = 1.06
