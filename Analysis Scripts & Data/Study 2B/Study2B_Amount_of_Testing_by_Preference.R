###################################
# Amount of Testing by Preference #
###################################

# Import Libary
library("tidyverse")
library('lsr') # used for "CohensD" function

# Import data
Study2B_Amount_of_Testing_by_Preference <- read.csv('Study2B_Amount_of_Testing_by_Preference.csv')

# preview data
head(Study2B_Amount_of_Testing_by_Preference)

# data dictionary: 
## "Participant" = participant number
## "Trial" = learning trial number (ranges: 0-151). Participants could only change input on trials 11-150 (1-10 were for learning purposes, and trial 151 was for final assessments of policies)
##  "F1_Pref_Policy" = Notes whether or not Function 1 was set to a preferred policy (coded as 1) or not (coded as 0); -88 denotes no participant preference (neutral stance) 
##  "F2_Pref_Policy" = Notes whether or not Function 2 was set to a preferred policy (coded as 1) or not (coded as 0); -88 denotes no participant preference (neutral stance) 
##  "F3_Pref_Policy" = Notes whether or not Function 3 was set to a preferred policy (coded as 1) or not (coded as 0); -88 denotes no participant preference (neutral stance) 
##  "F4_Pref_Policy" = Notes whether or not Function 4 was set to a preferred policy (coded as 1) or not (coded as 0); -88 denotes no participant preference (neutral stance) 
##  "F5_Pref_Policy" = Notes whether or not Function 5 was set to a preferred policy (coded as 1) or not (coded as 0); -88 denotes no participant preference (neutral stance) 
##  "F6_Pref_Policy" = Notes whether or not Function 6 was set to a preferred policy (coded as 1) or not (coded as 0); -88 denotes no participant preference (neutral stance)

# Filter to only include trials where participants had control over policy choice (trials 1-150).  
Study2B_Amount_of_Testing_by_Preference <- Study2B_Amount_of_Testing_by_Preference %>% 
  filter(Trial %in% c(11:150))

# Create dataframe with percent of preferred policy for each function
Study2B_Amount_of_Testing_by_Preference_Mean_Output <- Study2B_Amount_of_Testing_by_Preference %>%
  group_by(Participant) %>% 
  summarise_at(.vars = vars(F1_Pref_Policy,
                            F2_Pref_Policy,
                            F3_Pref_Policy,
                            F4_Pref_Policy,
                            F5_Pref_Policy,
                            F6_Pref_Policy
  ),
  .funs= c(mean="mean"), na.rm=TRUE)

# Remove instances of neutral policies for every participant and all six functions (neural policies are coded as "-88")
Study2B_Amount_of_Testing_by_Preference_Mean_Output$F1_Pref_Policy_mean_clean <- 
  ifelse(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F1_Pref_Policy_mean==-88,NA,
         Study2B_Amount_of_Testing_by_Preference_Mean_Output$F1_Pref_Policy_mean)
Study2B_Amount_of_Testing_by_Preference_Mean_Output$F2_Pref_Policy_mean_clean <- 
  ifelse(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F2_Pref_Policy_mean==-88,NA,
         Study2B_Amount_of_Testing_by_Preference_Mean_Output$F2_Pref_Policy_mean)
Study2B_Amount_of_Testing_by_Preference_Mean_Output$F3_Pref_Policy_mean_clean <- 
  ifelse(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F3_Pref_Policy_mean==-88,NA,
         Study2B_Amount_of_Testing_by_Preference_Mean_Output$F3_Pref_Policy_mean)
Study2B_Amount_of_Testing_by_Preference_Mean_Output$F4_Pref_Policy_mean_clean <- 
  ifelse(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F4_Pref_Policy_mean==-88,NA,
         Study2B_Amount_of_Testing_by_Preference_Mean_Output$F4_Pref_Policy_mean)
Study2B_Amount_of_Testing_by_Preference_Mean_Output$F5_Pref_Policy_mean_clean <- 
  ifelse(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F5_Pref_Policy_mean==-88,NA,
         Study2B_Amount_of_Testing_by_Preference_Mean_Output$F5_Pref_Policy_mean)
Study2B_Amount_of_Testing_by_Preference_Mean_Output$F6_Pref_Policy_mean_clean <- 
  ifelse(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F6_Pref_Policy_mean==-88,NA,
         Study2B_Amount_of_Testing_by_Preference_Mean_Output$F6_Pref_Policy_mean)

# examine output
head(Study2B_Amount_of_Testing_by_Preference_Mean_Output)

# functions for computing testing preference mean values for each participant (causal & non-causal functions analyzed separately)
compute_causal_function_testing_preference <- function(F1, F2, F3, F4){
  mean_output_array <- c()
  for (i in 1:length(F1)){
    participant_mean <- mean(c(F1[i][!is.na(F1[i])],
                               F2[i][!is.na(F2[i])],
                               F3[i][!is.na(F3[i])],
                               F4[i][!is.na(F4[i])]))
    mean_output_array <- append(mean_output_array, participant_mean, after = length(mean_output_array))
  }
  return(mean_output_array)
}

compute_non_causal_function_testing_preference <- function(F5, F6){
  mean_output_array <- c()
  for (i in 1:length(F5)){
    valid_input_count <- length(c(F5[i][!is.na(F5[i])],
                                  F6[i][!is.na(F6[i])]))
    participant_mean <- mean(c(F5[i][!is.na(F5[i])],
                               F6[i][!is.na(F6[i])]))
    participant_mean <- ifelse(valid_input_count==0,NA, participant_mean) # if participant had both non-causal functions with "neutral stances" than they submit a "NA" for this analysis
    mean_output_array <- append(mean_output_array, participant_mean, after = length(mean_output_array))
  }
  return(mean_output_array)
}

# compute causal mean testing preference
Study2B_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean <- 
  compute_causal_function_testing_preference(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F1_Pref_Policy_mean_clean,
                                             Study2B_Amount_of_Testing_by_Preference_Mean_Output$F2_Pref_Policy_mean_clean,
                                             Study2B_Amount_of_Testing_by_Preference_Mean_Output$F3_Pref_Policy_mean_clean,
                                             Study2B_Amount_of_Testing_by_Preference_Mean_Output$F4_Pref_Policy_mean_clean)

# compute non-causal mean testing preference
Study2B_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean <- 
  compute_non_causal_function_testing_preference(Study2B_Amount_of_Testing_by_Preference_Mean_Output$F5_Pref_Policy_mean_clean,
                                                 Study2B_Amount_of_Testing_by_Preference_Mean_Output$F6_Pref_Policy_mean_clean)

# Causal Functions: Descriptives
round(mean(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean, na.rm=TRUE),4)*100 # Mean = 64.43
round(sd(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean, na.rm=TRUE),4)*100 # Std dev = 30.21

# Causal Functions: one-sample t-test
t.test(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean, mu=.50) # t(279)=7.99, p < .001

# Causal Functions: Cohen's d (one-sample t-test)
cohensD(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Causal_Pref_Policy_mean, mu=.50) # d = .48

# Non-Causal Functions: Descriptives
round(mean(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean, na.rm=TRUE),4)*100 # Mean = 68.14
round(sd(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean, na.rm=TRUE),4)*100 # Std dev = 29.50

# Non-Causal Functions: one-sample t-test
t.test(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean, mu=.50) # t(225)=9.25, p < .001

# Non-Causal Functions: Cohen's d (one-sample t-test)
cohensD(Study2B_Amount_of_Testing_by_Preference_Mean_Output$Non_Causal_Pref_Policy_mean, mu=.50) # d = .62
